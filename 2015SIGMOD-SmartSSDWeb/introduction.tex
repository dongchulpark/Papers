
\section{Introduction}
%Jianguo: do we need to mention latency-centric application? instead of throughput-centric?
Solid state drives (SSDs) have gained much momentum in the storage market because of the compelling advantages of SSDs over hard disk drives (HDDs). E.g., SSDs are one to two orders of magnitude faster than HDDs in random reads~\cite{AthanassoulisACGS10}. In past years, many research works discussed how to \emph{make full use} of SSD in high level software systems (e.g., database systems) than just use SSD as yet anther faster HDD.
E.g., SSD-aware Btrees~\cite{Li2010TIS}, buffer management~\cite{Do2011TDB}. Those works share the same goal of optimizing software systems, while treating SSD as a storage-\emph{only} device. E.g., leveraging the tradeoff between different I/O access patterns. In this way, data storage and computing is rigorously \emph{separated}: data is store on SSD, while computing is at the host machine (CPU). Upon computation, data is transferred from SSD to the host machine through the host I/O interface (typically SAS or SATA).

However, recent works indicate this ``\emph{move data closer to code}" computing paradigm cannot make full use of SSD~\cite{Do2013QPS,WoodsIA14}, due to two reasons. (1) SSD provides much higher internal bandwidth (5$\times$ $\sim$ 10$\times$) than the host I/O interface bandwidth. However, data has to be transferred via the host I/O interface, which can saturate easily for data-intensive applications, making the high internal bandwidth of SSD wasteful; (2) SSD provides pretty high computing capability (for executing complex FTL firmware code~\cite{Chung2009SFT}), which is ignored by the high level systems by using SSD as a storage-\emph{only} device.

Thus, Jaeyoung et. al proposes an approach of integrating computing and storage inside SSD, which is termed as \emph{Smart SSD}~\cite{Do2013QPS} or \emph{SSD In-Storage Computing (ISC)}\footnote{In this work, we use the term ``Smart SSD" and ``SSD In-Storage Computing" interchangeably.}. Smart SSD allows the execution of application-specific code (e.g., database scan and aggregation) inside SSD, to take the advantage of the high internal bandwidth, low I/O latency and computing power. In this way, the computing paradigm is changed to ``\emph{move code closer to data}" (or generally near-data processing~\cite{Balasubramonian14}). In addition to the performance improvement, Smart SSD can also reduce energy significantly, because of the less data movement as well as the power-efficient processors running inside SSD. As a result, Smart SSD is a promising solution to \emph{make full use} of SSD. It is also attractive to industry. E.g., IBM deploys Smart SSD in their blue gene storage system~\cite{Julich13}.

This work explores how to apply Smart SSD to web search engine area. It is interesting to know whether web search engine can benefit from Smart SSD. The major research issue is, \emph{what query processing steps can be cost-effectively answered by Smart SSD}?
To answer this question, we identify five commonly used operations in web search engines that could be potentially benefit from Smart SSD: \textsf{intersection}, \textsf{ranked intersection}, \textsf{ranked union}, \textsf{difference}, and \textsf{ranked difference} and discuss the opportunities of the query offloading. We closely work with an SSD vendor to implement these operations to Smart SSD. We also integrate Smart SSD with an open-source search engine -- Apache Lucene\footnote{\url{http://lucene.apache.org}}. Finally, we conduct extensive experiments to evaluate the performance and tradeoffs by using both synthetic datasets and real datasets (provided by a commercial large-scale search engine company). The experimental results show that, Smart SSD can generally reduce the query latency by a factor of 2-3$\times$ and energy consumption by 8-10$\times$.

To the best of our knowledge, this is the first work to explore SSD in-storage computing to web search engine area. With the advent of SSD, the boundary between software system (i.e., web search engine systems in our case) and storage (i.e., SSD) is getting blur and blur~\cite{Steve12}. Thus, to fully utilize the advantages of SSD to search engine, this work shows that it is beneficial to consider a system co-design approach between search engine and SSD. In this way, computing power and storage are tightly integrated to improve the overall performance.

The rest of this paper is organized as follows.
Section~\ref{sec:background} provides an overview of SSD internal architecture, and a typical web search engine architecture.
Section~\ref{sec:ssdArch} describes how does our Smart SSD work.
Section~\ref{sec:design} discusses the integrated system design space and architecture of the Smart SSD and web search engine.
Section~\ref{sec:implementation} details the implementation of the query offloading.
Section~\ref{sec:expSetup} and Section~\ref{sec:expResults} show the evaluation, and discuss the tradeoffs of the query offloading.
Section~\ref{sec:relatedWork} discusses some related studies of this work.
Section~\ref{sec:conclusion} concludes the work.

